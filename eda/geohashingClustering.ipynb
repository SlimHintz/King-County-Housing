{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The problem \n",
    "\n",
    "The location data is latitude and longitude. I want to cluster together certains locations together and set new categories based on those clusters.\n",
    "\n",
    "Geohashing is one technique, but the underlying geometry is not perfectly euclidean (We are dealing with a globe after all), I have want to incorporate geodesic geometry. \n",
    "\n",
    "### The solution\n",
    "To do this I will first geohash the data and one hot encode it and run ols. Then, I will do the same thing using hdbscan\n",
    "\n",
    "\n",
    "#### I need to test the geohashing method ASAP! \n",
    "\n",
    "There is a good chance that I won't be able to match up the geo tags for the predictions.. \n",
    "I wonder how well this will work.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Geohash#Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import geohash2\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = np.array([[lat1, lon1], [lat2, lon2], ...])\n",
    "# rads = np.radians(points)\n",
    "# clusterer = hdbscan.HDBSCAN(min_cluster_size=N, metric='haversine')\n",
    "# cluster_labels = clusterer.fit_predict(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(\"../raw/kc_house_data_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2591820310</td>\n",
       "      <td>20141006T000000</td>\n",
       "      <td>365000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2070</td>\n",
       "      <td>8893</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2070</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>98058</td>\n",
       "      <td>47.4388</td>\n",
       "      <td>-122.162</td>\n",
       "      <td>2390</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7974200820</td>\n",
       "      <td>20140821T000000</td>\n",
       "      <td>865000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2900</td>\n",
       "      <td>6730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1830</td>\n",
       "      <td>1070</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6784</td>\n",
       "      <td>-122.285</td>\n",
       "      <td>2370</td>\n",
       "      <td>6283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7701450110</td>\n",
       "      <td>20140815T000000</td>\n",
       "      <td>1038000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3770</td>\n",
       "      <td>10893</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3770</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5646</td>\n",
       "      <td>-122.129</td>\n",
       "      <td>3710</td>\n",
       "      <td>9685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9522300010</td>\n",
       "      <td>20150331T000000</td>\n",
       "      <td>1490000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4560</td>\n",
       "      <td>14608</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4560</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>98034</td>\n",
       "      <td>47.6995</td>\n",
       "      <td>-122.228</td>\n",
       "      <td>4050</td>\n",
       "      <td>14226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9510861140</td>\n",
       "      <td>20140714T000000</td>\n",
       "      <td>711000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550</td>\n",
       "      <td>5376</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2550</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.6647</td>\n",
       "      <td>-122.083</td>\n",
       "      <td>2250</td>\n",
       "      <td>4050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  2591820310  20141006T000000   365000.0         4       2.25         2070   \n",
       "1  7974200820  20140821T000000   865000.0         5       3.00         2900   \n",
       "2  7701450110  20140815T000000  1038000.0         4       2.50         3770   \n",
       "3  9522300010  20150331T000000  1490000.0         3       3.50         4560   \n",
       "4  9510861140  20140714T000000   711000.0         3       2.50         2550   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      8893     2.0           0     0  ...      8        2070              0   \n",
       "1      6730     1.0           0     0  ...      8        1830           1070   \n",
       "2     10893     2.0           0     2  ...     11        3770              0   \n",
       "3     14608     2.0           0     2  ...     12        4560              0   \n",
       "4      5376     2.0           0     0  ...      9        2550              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1986             0    98058  47.4388 -122.162           2390   \n",
       "1      1977             0    98115  47.6784 -122.285           2370   \n",
       "2      1997             0    98006  47.5646 -122.129           3710   \n",
       "3      1990             0    98034  47.6995 -122.228           4050   \n",
       "4      2004             0    98052  47.6647 -122.083           2250   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        7700  \n",
       "1        6283  \n",
       "2        9685  \n",
       "3       14226  \n",
       "4        4050  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pd dataframe using haversine density scanning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a np array called pointer containg the latitude and longitude of each obs\n",
    "points = np.array(list(zip(df.lat, df.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01445068, -0.03721267])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the points from degrees to radians\n",
    "points = np.radians(points)\n",
    "points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our haversine clustering object \n",
    "N = 15\n",
    "min_size = 5\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=N, metric='haversine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the clusterer to our data\n",
    "cluster_labels = clusterer.fit_predict(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = cluster_labels.tolist()\n",
    "clusters = pd.DataFrame(pd.Series(clusters))\n",
    "clusters.columns = ['hdb_clusters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.get_dummies(clusters.hdb_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.to_csv(\"../cleanedData/hdb_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-fd47701cd990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "neigh.fit(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get holdout geohashing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw/kc_holdout_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(list(zip(df.lat, df.long)))\n",
    "points = np.radians(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Create a function to apply the geohashing function to the lat and long columns.\n",
    "\n",
    "def geo_hash(lat, long):\n",
    "    return geohash2.encode(lat, long, 5)\n",
    "\n",
    "# pull out the latitude and longitude data\n",
    "location = df[['lat', 'long']]\n",
    "\n",
    "location['hashed_location'] = location.apply(lambda x: geo_hash(x['lat'], x['long']), axis=1)\n",
    "# apply the geo_has function to the latitude and longitude columns of the dataframe\n",
    "# location.apply(geo_hash(location), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>hashed_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.7089</td>\n",
       "      <td>-122.241</td>\n",
       "      <td>c23p6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.7089</td>\n",
       "      <td>-122.241</td>\n",
       "      <td>c23p6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.5472</td>\n",
       "      <td>-121.998</td>\n",
       "      <td>c23nr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.7427</td>\n",
       "      <td>-122.071</td>\n",
       "      <td>c23pw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.4863</td>\n",
       "      <td>-122.140</td>\n",
       "      <td>c23nh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>c22zr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>c22yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>c23nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>c23nq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>c23nc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4323 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lat     long hashed_location\n",
       "0     47.7089 -122.241           c23p6\n",
       "1     47.7089 -122.241           c23p6\n",
       "2     47.5472 -121.998           c23nr\n",
       "3     47.7427 -122.071           c23pw\n",
       "4     47.4863 -122.140           c23nh\n",
       "...       ...      ...             ...\n",
       "4318  47.6993 -122.346           c22zr\n",
       "4319  47.5107 -122.362           c22yr\n",
       "4320  47.5944 -122.299           c23nc\n",
       "4321  47.5345 -122.069           c23nq\n",
       "4322  47.5941 -122.299           c23nc\n",
       "\n",
       "[4323 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insure holdout and regular have the same number of dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dummy_geo = pd.get_dummies(location.hashed_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_holdout_geo = set(dummy_geo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.read_csv('../cleanedData/geohashed_full.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_geo = set(geo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c23hq'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set_holdout_geo.difference(set_geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4323, 178), (17290, 196))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_geo.shape, geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "196-178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_holdout_geo = geo.drop(columns= list(set_geo.difference(set_holdout_geo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out by 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c22uz', 'c22vm', 'c22vn', 'c22vp', 'c22vr', 'c22vs', 'c22vt', 'c22vu',\n",
       "       'c22vv', 'c22vw',\n",
       "       ...\n",
       "       'c23r2', 'c23r3', 'c23r4', 'c23r6', 'c23r8', 'c23r9', 'c23rd', 'c23rf',\n",
       "       'c23xm', 'c23xq'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_holdout_geo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(overlap_holdout_geo).difference(set_holdout_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17290, 177)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_holdout_geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c22uz', 'c22vm', 'c22vn', 'c22vp', 'c22vr', 'c22vs', 'c22vt', 'c22vu',\n",
       "       'c22vv', 'c22vw',\n",
       "       ...\n",
       "       'c23r2', 'c23r3', 'c23r4', 'c23r6', 'c23r8', 'c23r9', 'c23rd', 'c23rf',\n",
       "       'c23xm', 'c23xq'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_holdout_geo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(dummy_geo.columns) + list(geo.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_geo = dummy_geo.drop(columns=['c23hq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(holdout_geo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 177 overlapping hashed regions! Save to csv and let's gooooo\n",
    "\n",
    "holdout_geo.to_csv('../cleanedData/holdoutGeo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 21)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_holdout_geo.to_csv('../cleanedData/geoOverlap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
